{"posts":[{"title":"Python-Process-Thread-Coroutine-GIL","text":"Python进程、线程、协程、GIL基础概念进程(Process)进程是操作系统分配资源的基本单位，每个进程都有自己的内存空间、代码段、数据段、堆栈等。进程的特点是： 独立性强：一个进程崩溃不会直接影响其他进程。 系统开销大：创建和切换进程需要操作系统切换上下文和内存管理。 进程间通信（IPC）复杂：常用方法有管道、消息队列、共享内存、socket等。 线程(Thread)线程是CPU调度的基本单位，是比进程更小的执行单元。线程属于进程，多个线程共享进程的内存空间。线程的特点是： 轻量级：创建、切换开销比进程小。 数据共享：同一进程内线程共享全局变量和堆内存，但要注意线程安全（加锁）。 受GIL限制：Python中同一时刻只能有一个线程执行Python字节码，因此CPU 密集型任务无法通过多线程实现真正并行。 协程(Coroutine)协程是一种用户态的轻量级线程，也叫微线程，特点是非抢占式调度。协程依赖事件循环，在I/O等待时主动让出控制权，节省线程切换开销，协程只在一个线程中运行，但可以同时处理大量I/O任务。协程的特点是： 极轻量：成千上万协程在一个线程中也不占用大量内存。 非抢占式：需要显式await或yield才会切换。 适合I/O密集型任务。 全局解释器锁(GIL)GIL是Python的一把锁，用来保证同一时刻只有一个线程执行Python 字节码。GIL存在是为了简化内存管理。GIL会导致多线程无法利用多核CPU做CPU密集型运算，I/O 密集型任务不受影响。 具体实现 使用multiprocessing实现多进程 123456789101112131415161718192021222324252627282930313233343536373839import multiprocessingimport osimport timedef process_task(task_name: str): print(f&quot;Process {task_name} started,PID: {os.getpid()},Time:{time.time()}&quot;) time.sleep(5) print(f&quot;Process {task_name} finished,time:{time.time()}&quot;)'''-------------start-----------------父进程 | |-- p.start() |操作系统： ├─ 创建新进程（PID 不同） ├─ 分配独立内存空间 ├─ 拷贝/初始化运行环境 └─ 调度子进程执行-------------join-----------------父进程：WAITING子进程：RUNNING↓子进程退出↓父进程恢复执行'''if __name__ == &quot;__main__&quot;: tasks = [&quot;Task 1&quot;, &quot;Task 2&quot;, &quot;Task 3&quot;] processes = [] for task in tasks: p = multiprocessing.Process(target=process_task, args=(task,)) processes.append(p) p.start() # 让OS调度进程,创建并启动一个并发执行单元 for p in processes: p.join() # 阻塞当前进程（通常是父进程），直到子进程结束 output: 123456Process Task 2 started,PID: 5936,Time:1768805990.6005492Process Task 1 started,PID: 5935,Time:1768805990.600867Process Task 3 started,PID: 5937,Time:1768805990.602313Process Task 2 finished,time:1768805995.602974Process Task 1 finished,time:1768805995.605867Process Task 3 finished,time:1768805995.608462 使用threading创建多线程 1234567891011121314151617181920212223242526272829303132333435363738import threadingimport osimport timedef thread_task(task_name: str): print(f&quot;Thread {task_name} started,PID: {os.getpid()},Time:{time.time()}&quot;) time.sleep(5) print(f&quot;Thread {task_name} finished,time:{time.time()}&quot;) '''-------------start-----------------进程 ├─ 主线程 └─ 子线程（共享内存）start(): ├─ 创建 OS 线程 ├─ 注册到当前进程 └─ 等待 CPU 调度-------------join-----------------主线程：WAITING子线程：RUNNING↓子线程结束↓主线程继续'''if __name__ == &quot;__main__&quot;: tasks = [&quot;Task 1&quot;, &quot;Task 2&quot;, &quot;Task 3&quot;] threads = [] for task in tasks: t = threading.Thread(target=thread_task, args=(task,)) threads.append(t) # 在当前进程内创建一个新的执行线程，并执行task t.start() for t in threads: t.join() # 阻塞当前线程，直到目标线程执行结束 output: 123456Thread Task 1 started,PID: 6098,Time:1768806447.717162Thread Task 2 started,PID: 6098,Time:1768806447.717246Thread Task 3 started,PID: 6098,Time:1768806447.717311Thread Task 1 finished,time:1768806452.721641Thread Task 2 finished,time:1768806452.724179Thread Task 3 finished,time:1768806452.724231 使用asyncio实现协程 12345678910111213141516171819202122232425262728293031323334353637383940414243444546import asyncioimport timeasync def task(task_name: str): print(f&quot;task {task_name} start,time:{time.time()}&quot;) await asyncio.sleep(5) print(f&quot;task {task_name} end,time:{time.time()}&quot;)'''asyncio.run() ├─ 创建事件循环 ├─ 创建 main Task ├─ 启动事件循环 └─ main 执行 └─ await gather ├─ 注册 task1/2/3 ├─ 并发调度 └─ 等待全部完成 ├─ main 结束 └─ 关闭事件循环'''async def main(): tasks = [task(str(i)) for i in range(3)] await asyncio.gather(*tasks) ''' 协程对象: → create_task() → Task（Future） → 注册到事件循环 gather: 创建一个新的 Future 监听所有子 Task 等全部完成 收集结果 --------------时间线--------------- A start ─┐ B start ─┼── 并发执行 C start ─┘ ↓ await（让出控制权） ↓ 事件循环调度 '''asyncio.run(main()) output:协程的输出几乎同时开始，节省了线程的切换开销，非常高效 123456task 0 start,time:1768807095.176304task 1 start,time:1768807095.176335task 2 start,time:1768807095.176345task 0 end,time:1768807100.1782029task 1 end,time:1768807100.178287task 2 end,time:1768807100.178303 线程安全加锁的实现 同步锁Lock,不支持多次申请和多次释放 递归锁RLock支持多次申请锁acquire()和多次释放锁release() 123456789101112131415161718192021222324252627282930import threadingnumber = 0thread_lock = threading.RLock() # 递归锁def task_add(): # 使用线程锁上下文申请锁 with thread_lock: global number for i in range(1000): number += i print(f&quot;Number is {number},Thread name is {threading.current_thread().name}&quot;)def task_sub(): with thread_lock: global number for i in range(1000): number -= i print(f&quot;Number is {number},Thread name is {threading.current_thread().name}&quot;)add_thread = threading.Thread(target=task_add)add_thread.name = &quot;add_thread&quot;sub_thread = threading.Thread(target=task_sub)sub_thread.name = &quot;sub_thread&quot;add_thread.start()sub_thread.start() output: 12Number is 499500,Thread name is add_threadNumber is 0,Thread name is sub_thread","link":"/2026/01/19/Python-Process-Thread-Coroutine-GIL/"},{"title":"Python单例模式","text":"单例模式介绍一个类在整个系统运行期间，只允许存在一个实例，并提供全局访问点。应用的场景： 配置只能加载一次 日志对象不能创建多个 数据库连接池只需要一个 Redis / MQ 客户端只要一个 全局状态管理器（限流、缓存等） 单例模式的实现12345678910111213141516import threadingclass Singleton: _instances = None _lock = threading.RLock() def __init__(self, *args, **kwargs): super().__init__(*args, **kwargs) def __new__(cls, *args, **kwargs): if not cls._instances: # 性能更好，已经创建了对象后不需要再申请锁和释放锁 with cls._lock: if not cls._instances: cls._instances = super().__new__(cls) return cls._instances","link":"/2026/01/20/Python%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"},{"title":"Python线程池","text":"线程池介绍Python3 中标准线程池实现位于：concurrent.futures.thread.ThreadPoolExecutor，它于 Python 3.2 引入，目的是： 统一线程 / 进程并发模型 屏蔽线程创建、销毁的成本 提供 Future 异步结果接口 简化并发代码结构 主要类关系： 12345Executor └── ThreadPoolExecutor ├── Worker threads ├── WorkQueue └── Future 核心对象： 组件 作用 ThreadPoolExecutor 线程池管理器 threading.Thread 实际执行任务的工作线程 queue.Queue 任务队列（FIFO） Future 任务结果占位符 _WorkItem 任务封装单元 线程池调度Python 线程池使用的是：集中式任务队列 + 抢占式获取任务。 12345+-------------------+| Queue (FIFO) |+-------------------+ ↑ ↑ ↑Worker Worker Worker 任务调度是FIFO使用queue.Queue。线程调用是竞争式，所有worker线程阻塞在queue.get()，哪个线程被OS唤醒哪个线程先执行。 具体实现12345678910111213141516171819202122232425262728from concurrent.futures import ThreadPoolExecutorpool = ThreadPoolExecutor(max_workers=10)number = 0def task_add(add_number=1): global number number += add_number return numberdef task_get(future): print(f&quot;Currner Number is {future.result()}&quot;)future_list = []# 一次性将任务提交给线程池for item in range(int(1e4)): future = pool.submit(task_add, item) future_list.append(future) if item % 1000 == 0: future.add_done_callback(task_get) # 线程执行完成后的回调print(&quot;Loop End&quot;)pool.shutdown(wait=True) # 等待线程池中的任务全部执行完成sum_count = sum([future.result() for future in future_list])print(f&quot;End,Sum Count is:{sum_count},Current Number is:{future_list[1000].result()}&quot;) output: 123456789101112Currner Number is 0Currner Number is 500212Currner Number is 2000749Currner Number is 4501249Currner Number is 7968646Currner Number is 12472848Currner Number is 17965886Currner Number is 40476059Currner Number is 31970260Currner Number is 24471687Loop EndEnd,Sum Count is:166778486073,Current Number is:500212","link":"/2026/01/19/Python%E7%BA%BF%E7%A8%8B%E6%B1%A0/"}],"tags":[{"name":"Python","slug":"Python","link":"/tags/Python/"}],"categories":[],"pages":[]}